{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. SwinTran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch import nn\n",
    "from timm import create_model\n",
    "\n",
    "\n",
    "class SwinTransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes, fine_tune=False):\n",
    "        super(SwinTransformerModel, self).__init__()\n",
    "        self.swin = create_model(\n",
    "            'swin_large_patch4_window7_224.ms_in22k', \n",
    "            pretrained=True,\n",
    "            num_classes=num_classes,\n",
    "            in_chans=1\n",
    "        )\n",
    "        \n",
    "        if not fine_tune:\n",
    "            for param in self.swin.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            for param in self.swin.head.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.swin(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SwinTransformerModel(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "print()\n",
    "\n",
    "x = torch.randn(1, 1, IMAGE_SIZE[0], IMAGE_SIZE[1]).to(device)\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "print(\"Model output's shape:\", output.shape)\n",
    "print(output)\n",
    "display_params_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinTransformerModel(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Unetr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch.nn as nn\n",
    "from monai.networks.blocks.dynunet_block import UnetOutBlock\n",
    "from monai.networks.blocks.unetr_block import UnetrBasicBlock, UnetrPrUpBlock, UnetrUpBlock\n",
    "\n",
    "\n",
    "class DaViT_UnetR_Modelv2(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True, fine_tune=False):\n",
    "        super(DaViT_UnetR_Modelv2, self).__init__()\n",
    "        \n",
    "        self.davit = timm.create_model('davit_base.msft_in1k', pretrained=pretrained, features_only=True, in_chans=1)\n",
    "        \n",
    "        if not fine_tune:\n",
    "            for param in self.davit.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        \n",
    "        spatial_dims = 2 \n",
    "        in_channels = 1 # R,G,B\n",
    "        feature_size = 128\n",
    "        norm_name = \"instance\"\n",
    "        hidden_size = 128\n",
    "        res_block = True\n",
    "        conv_block = False\n",
    "\n",
    "        self.encoder1 = UnetrBasicBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        self.encoder2 = UnetrPrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=hidden_size,\n",
    "            out_channels=feature_size * 2,\n",
    "            num_layer=2,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            upsample_kernel_size=1,\n",
    "            norm_name=norm_name,\n",
    "            conv_block=conv_block,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        self.encoder3 = UnetrPrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=hidden_size*2,\n",
    "            out_channels=feature_size * 4,\n",
    "            num_layer=1,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            upsample_kernel_size=1,\n",
    "            norm_name=norm_name,\n",
    "            conv_block=conv_block,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        self.encoder4 = UnetrPrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=hidden_size*4,\n",
    "            out_channels=feature_size * 8,\n",
    "            num_layer=0,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            upsample_kernel_size=1,\n",
    "            norm_name=norm_name,\n",
    "            conv_block=conv_block,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        self.decoder5 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=hidden_size * 8,\n",
    "            out_channels=feature_size * 8,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        self.decoder4 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size * 8,\n",
    "            out_channels=feature_size * 4,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        self.decoder3 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size * 4,\n",
    "            out_channels=feature_size * 2,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        self.decoder2 = UnetrUpBlock(\n",
    "            spatial_dims=spatial_dims,\n",
    "            in_channels=feature_size * 2,\n",
    "            out_channels=feature_size,\n",
    "            kernel_size=3,\n",
    "            upsample_kernel_size=2,\n",
    "            norm_name=norm_name,\n",
    "            res_block=res_block,\n",
    "        )\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(feature_size, 78, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(78, 50, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2450, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x_in):\n",
    "        \n",
    "        hidden_states_out = self.davit(x_in)\n",
    "\n",
    "        enc1 = self.encoder1(x_in)\n",
    "        \n",
    "        x2 = hidden_states_out[0]\n",
    "        enc2 = self.encoder2(x2)\n",
    "        \n",
    "        x3 = hidden_states_out[1]\n",
    "        enc3 = self.encoder3(x3)\n",
    "        \n",
    "        x4 = hidden_states_out[2]\n",
    "        enc4 = self.encoder4(x4)\n",
    "\n",
    "        dec4 = hidden_states_out[3]\n",
    "\n",
    "        dec3 = self.decoder5(dec4, enc4)\n",
    "        \n",
    "        dec2 = self.decoder4(dec3, enc3)\n",
    "\n",
    "        dec1 = self.decoder3(dec2, enc2)\n",
    "\n",
    "        out = self.decoder2(dec1, enc1) \n",
    " \n",
    "        conv_out = self.conv(out)\n",
    "\n",
    "        return self.classifier(conv_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DaViT_UnetR_Modelv2(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "print()\n",
    "\n",
    "x = torch.randn(1, 1, IMAGE_SIZE[0], IMAGE_SIZE[1]).to(device)\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "print(\"Model output's shape:\", output.shape)\n",
    "print(output)\n",
    "display_params_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DaViT_UnetR_Modelv2(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. CoAtNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch import nn\n",
    "from timm import create_model\n",
    "\n",
    "\n",
    "class CoatNetModel(nn.Module):\n",
    "    def __init__(self, num_classes, fine_tune=False):\n",
    "        super(CoatNetModel, self).__init__()\n",
    "        self.coatnet = create_model(\n",
    "            'timm/coatnet_3_rw_224.sw_in12k',\n",
    "            pretrained=True,\n",
    "            num_classes=num_classes,\n",
    "            in_chans=1\n",
    "        )\n",
    "        \n",
    "        if not fine_tune:\n",
    "            for param in self.coatnet.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            for param in self.coatnet.head.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.coatnet(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CoatNetModel(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "print()\n",
    "\n",
    "x = torch.randn(1, 1, IMAGE_SIZE[0], IMAGE_SIZE[1]).to(device)\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "print(\"Model output's shape:\", output.shape)\n",
    "print(output)\n",
    "display_params_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CoatNetModel(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class VGG19Model(nn.Module):\n",
    "    def __init__(self, num_classes, fine_tune=False):\n",
    "        super(VGG19Model, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.vgg19 = models.vgg19(pretrained=True)\n",
    "        \n",
    "        if not fine_tune:\n",
    "            for param in self.vgg19.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for param in self.vgg19.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "            \n",
    "\n",
    "        in_features = self.vgg19.classifier[6].in_features\n",
    "\n",
    "        self.vgg19.classifier[6] = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.vgg19(x)\n",
    "        return x\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VGG19Model(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "print()\n",
    "\n",
    "x = torch.randn(1, 1, IMAGE_SIZE[0], IMAGE_SIZE[1]).to(device)\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "print(\"Model output's shape:\", output.shape)\n",
    "print(output)\n",
    "display_params_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG19Model(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 3e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "from torch import nn\n",
    "from timm import create_model\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True, fine_tune=False):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        self.densenet = create_model(\n",
    "            'densenet121.tv_in1k', \n",
    "            pretrained=pretrained,\n",
    "            num_classes=num_classes,\n",
    "            in_chans=1\n",
    "        )\n",
    "\n",
    "        if not fine_tune:\n",
    "            for param in self.densenet.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            for param in self.densenet.global_pool.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            for param in self.densenet.head_drop.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            for param in self.densenet.classifier.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.densenet(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNetModel(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "print()\n",
    "\n",
    "x = torch.randn(1, 1, IMAGE_SIZE[0], IMAGE_SIZE[1]).to(device)\n",
    "\n",
    "\n",
    "output = model(x)\n",
    "print(\"Model output's shape:\", output.shape)\n",
    "print(output)\n",
    "display_params_flops(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DenseNetModel(num_classes, fine_tune=False)\n",
    "model.to(device)\n",
    "\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 3e-5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
